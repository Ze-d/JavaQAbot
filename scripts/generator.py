import os
import pandas as pd
import numpy as np
from langchain_chroma import Chroma
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances_argmin_min
from utils import get_llm_model, get_embeddings_model
from ragas.testset import TestsetGenerator
from ragas.llms import LangchainLLMWrapper
from ragas.embeddings import LangchainEmbeddingsWrapper
from langchain_core.documents import Document
import warnings

warnings.filterwarnings('ignore')

# =================é…ç½®åŒºåŸŸ=================
CHROMA_DB_DIR = './data/db'
EVALUATOR_MODEL = 'deepseek-chat'
TESTSET_FILE = "auto_generated_testset.csv"
N_CLUSTERS = 200  # ç­›é€‰åçš„ä»£è¡¨æ€§æ–‡æ¡£æ•°
TESTSET_SIZE = 15  # ç”Ÿæˆçš„æµ‹è¯•é—®é¢˜æ•°


# =========================================

def main():
    print("ğŸš€ å¼€å§‹ç”Ÿæˆæµ‹è¯•é›†æµç¨‹...")

    # 1. åˆå§‹åŒ–æ¨¡å‹ï¼ˆå…¼å®¹æ—§ç‰ˆ Ragas Wrapperï¼‰
    print("ğŸ”§ åˆå§‹åŒ– LLM å’ŒåµŒå…¥æ¨¡å‹...")
    llm = get_llm_model()
    embedding_function = get_embeddings_model()
    generator_llm = LangchainLLMWrapper(llm)
    generator_embeddings = LangchainEmbeddingsWrapper(embedding_function)

    # 2. ä» Chroma åŠ è½½æ•°æ®
    print("ğŸ“– ä» Chroma æ•°æ®åº“åŠ è½½æ–‡æ¡£...")
    vectorstore = Chroma(
        persist_directory=CHROMA_DB_DIR,
        embedding_function=embedding_function
    )
    db_data = vectorstore.get()
    texts = db_data['documents']
    metadatas = db_data['metadatas']
    print(f"âœ… æˆåŠŸåŠ è½½ {len(texts)} ä¸ªæ–‡æ¡£ç‰‡æ®µã€‚")

    # 3. æ–‡æ¡£ç­›é€‰ï¼šK-Means èšç±»ï¼ˆæ ¸å¿ƒæé€Ÿï¼Œä¸å¯çœï¼‰
    if len(texts) > N_CLUSTERS:
        print(f"âš¡ æ–‡æ¡£æ•°é‡è¿‡å¤šï¼Œæ­£åœ¨ä½¿ç”¨ K-Means èšç±»ç­›é€‰ {N_CLUSTERS} ä¸ªä»£è¡¨æ€§æ–‡æ¡£...")

        all_doc_ids = db_data['ids']
        batch_size = 1000
        all_embeddings = []
        for i in range(0, len(all_doc_ids), batch_size):
            batch_ids = all_doc_ids[i:i + batch_size]
            batch_data = vectorstore.get(ids=batch_ids, include=['embeddings'])
            all_embeddings.extend(batch_data['embeddings'])

        embeddings_array = np.array(all_embeddings)
        kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(embeddings_array)
        closest_indices, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, embeddings_array)

        selected_texts = [texts[i] for i in closest_indices]
        selected_metadatas = [metadatas[i] for i in closest_indices]
        print(f"âœ… ç­›é€‰å®Œæˆï¼Œå…±é€‰æ‹© {len(selected_texts)} ä¸ªä»£è¡¨æ€§æ–‡æ¡£ç‰‡æ®µã€‚")
    else:
        selected_texts = texts
        selected_metadatas = metadatas
        print("â„¹ï¸  æ–‡æ¡£æ•°é‡è¾ƒå°‘ï¼Œä½¿ç”¨å…¨éƒ¨æ–‡æ¡£ç”Ÿæˆæµ‹è¯•é›†ã€‚")

    # 4. ç»ˆææŠ€å·§ï¼šåˆå¹¶æ‰€æœ‰æ–‡æ¡£ä¸ºä¸€ä¸ªé•¿æ–‡æœ¬ï¼Œå½»åº•ç»•å¼€åˆ†æ®µå’Œ headlines ä¾èµ–
    print("ğŸ“„ åˆå¹¶æ–‡æ¡£ä¸ºé•¿æ–‡æœ¬ï¼Œç»•å¼€æ‰€æœ‰åˆ†æ®µé€»è¾‘...")
    # æ—§ç‰ˆ Ragas å¯¹å•æ–‡æœ¬ç”Ÿæˆé—®é¢˜æ›´ç¨³å®šï¼Œæ— åˆ†æ®µä¾èµ–
    combined_text = "\n\n---\n\n".join(selected_texts)  # ç”¨åˆ†éš”ç¬¦åˆå¹¶æ‰€æœ‰æ–‡æ¡£
    # æ„é€ å•ä¸ª Documentï¼ˆæ— ä»»ä½•é¢å¤–å­—æ®µï¼Œé¿å…å…ƒæ•°æ®é—®é¢˜ï¼‰
    documents = [Document(page_content=combined_text, metadata={})]

    # 5. åˆå§‹åŒ– Ragas ç”Ÿæˆå™¨ï¼ˆæç®€æ¨¡å¼ï¼‰
    print("ğŸ§  æ­£åœ¨ä½¿ç”¨ Ragas ç”Ÿæˆæµ‹è¯•é›†ï¼ˆç»ˆæå…¼å®¹æ¨¡å¼ï¼‰...")
    generator = TestsetGenerator(
        llm=generator_llm,
        embedding_model=generator_embeddings
    )

    # 6. ç”Ÿæˆæµ‹è¯•é›†ï¼ˆä»…ç”¨æ—§ç‰ˆæ”¯æŒçš„å‚æ•°ï¼Œä¸è§¦å‘ä»»ä½•åˆ†æ®µï¼‰
    try:
        # ç¬¬ä¸€æ¬¡å°è¯•ï¼šç”¨ generate_with_langchain_docs å¤„ç†å•ä¸ªæ–‡æ¡£ï¼ˆæ— åˆ†æ®µéœ€æ±‚ï¼‰
        testset = generator.generate_with_langchain_docs(
            documents=documents,
            testset_size=TESTSET_SIZE
        )
    except Exception as e:
        # ç¬¬äºŒæ¬¡å°è¯•ï¼šç›´æ¥ç”¨ LLM åŸºäºé•¿æ–‡æœ¬ç”Ÿæˆé—®é¢˜ï¼ˆç»•å¼€ Ragas å†…éƒ¨å¤„ç†ï¼‰
        print(f"âš ï¸  è‡ªåŠ¨é€‚é…æ—§ç‰ˆ Ragasï¼š{str(e)[:50]}")
        from ragas.testset.synthesizers import QuestionGenerator
        # æ‰‹åŠ¨åˆå§‹åŒ–é—®é¢˜ç”Ÿæˆå™¨ï¼Œç›´æ¥ç”Ÿæˆé—®é¢˜
        qg = QuestionGenerator(llm=generator_llm)
        questions = qg.generate(
            contexts=[combined_text],  # æ—§ç‰ˆæ”¯æŒçš„å‚æ•°å
            num_questions=TESTSET_SIZE
        )
        # æ„é€ æµ‹è¯•é›†æ ¼å¼ï¼ˆé€‚é…åç»­è¯„ä¼°ï¼‰
        test_data = {
            'user_input': questions,
            'reference': [combined_text[:500] + "..." for _ in questions],  # æˆªå–éƒ¨åˆ†ä½œä¸ºå‚è€ƒ
            'reference_contexts': [selected_texts for _ in questions]
        }
        test_df = pd.DataFrame(test_data)
        # è·³è¿‡ Ragas åŸç”Ÿ testsetï¼Œç›´æ¥ä¿å­˜
        test_df.to_csv(TESTSET_FILE, index=False, encoding='utf-8-sig')
        print(f"\nğŸ‰ æµ‹è¯•é›†ç”Ÿæˆå®Œæ¯•ï¼å·²ä¿å­˜è‡³ {TESTSET_FILE}")
        print("é¢„è§ˆå‰2æ¡æ•°æ®ï¼š")
        print(test_df[['user_input', 'reference']].head(2))
        return

    # 7. ä¿å­˜æµ‹è¯•é›†ï¼ˆé€‚é…åç»­è¯„ä¼°ï¼‰
    test_df = testset.to_pandas()
    test_df.rename(columns={
        'question': 'user_input',
        'ground_truth': 'reference'
    }, inplace=True)
    test_df['reference_contexts'] = [selected_texts] * len(test_df)

    test_df.to_csv(TESTSET_FILE, index=False, encoding='utf-8-sig')
    print(f"\nğŸ‰ æµ‹è¯•é›†ç”Ÿæˆå®Œæ¯•ï¼å·²ä¿å­˜è‡³ {TESTSET_FILE}")
    print("é¢„è§ˆå‰2æ¡æ•°æ®ï¼š")
    print(test_df[['user_input', 'reference']].head(2))


if __name__ == "__main__":
    main()