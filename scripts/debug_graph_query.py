"""
å›¾æ•°æ®åº“æŸ¥è¯¢è°ƒè¯•è„šæœ¬
è¯¦ç»†æŸ¥çœ‹æ¯ä¸ªæ­¥éª¤çš„æ‰§è¡Œæƒ…å†µï¼Œæ‰¾å‡ºåŒ¹é…ä¸åˆ°æ¨¡æ¿çš„åŸå› 

ä½œè€…ï¼šzjy
"""

import os
import sys
import json
from typing import List

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.agents.structured_output import ToolStrategy
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS
from pydantic import BaseModel, Field

from src.utils.utils import get_llm_model, get_embeddings_model, replace_token_in_string
from src.core.config import GRAPH_TEMPLATE
from src.prompts.prompt import NER_PROMPT_TPL
from src.utils.logger_config import setup_logger

# è®¾ç½®æ—¥å¿—
logger_debug = setup_logger('GraphDebug', 'DEBUG')


def debug_graph_query(query: str):
    """è¯¦ç»†è°ƒè¯•å›¾æ•°æ®åº“æŸ¥è¯¢æµç¨‹"""

    print("=" * 80)
    print(f"ğŸ” å›¾æ•°æ®åº“æŸ¥è¯¢è°ƒè¯• - é—®é¢˜: {query}")
    print("=" * 80)

    # æ­¥éª¤1ï¼šå®šä¹‰JavaæŠ€æœ¯å®ä½“æå–æ¨¡å‹
    print("\nğŸ“‹ æ­¥éª¤1: å®šä¹‰NERæ¨¡å‹")
    class JavaTech(BaseModel):
        class_or_interface: List[str] = Field(default=[], description="Javaç±»æˆ–æ¥å£å®ä½“")
        framework: List[str] = Field(default=[], description="Javaæ¡†æ¶å®ä½“")
        method_name: List[str] = Field(default=[], description="Javaæ–¹æ³•å®ä½“")
        technology: List[str] = Field(default=[], description="JavaæŠ€æœ¯å®ä½“")

    print("   âœ… æ¨¡å‹å®šä¹‰å®Œæˆ")
    print(f"   å­—æ®µ: {list(JavaTech.model_fields.keys())}")

    # æ­¥éª¤2-3ï¼šé…ç½®ç»“æ„åŒ–è¾“å‡º
    print("\nğŸ“‹ æ­¥éª¤2-3: é…ç½®è¾“å‡ºè§£æå™¨")
    response_schemas = ToolStrategy(JavaTech)
    format_instructions = response_schemas
    output_parser = StrOutputParser(response_schemas=response_schemas)
    print("   âœ… è¾“å‡ºè§£æå™¨é…ç½®å®Œæˆ")

    # æ­¥éª¤4-5ï¼šæ‰§è¡Œå®ä½“æå–
    print("\nğŸ“‹ æ­¥éª¤4-5: æ‰§è¡ŒNERå®ä½“æå–")
    ner_prompt = PromptTemplate(
        template=NER_PROMPT_TPL,
        partial_variables={'format_instructions': format_instructions},
        input_variables=['query']
    )

    llm = get_llm_model()
    ner_chain = ner_prompt | llm

    try:
        ner_response = ner_chain.invoke({'query': query})
        print(f"   ğŸ” åŸå§‹LLMå“åº”: {ner_response.content[:200]}...")

        parsed_str = output_parser.parse(ner_response.content)
        print(f"   ğŸ” è§£æåçš„å­—ç¬¦ä¸²: {parsed_str[:200]}...")

        ner_result = json.loads(parsed_str)
        print(f"   âœ… NERæå–ç»“æœ:")
        for key, value in ner_result.items():
            print(f"      {key}: {value}")

        # æ£€æŸ¥æ˜¯å¦æœ‰æå–åˆ°å®ä½“
        has_entities = any([
            ner_result.get('class_or_interface', []),
            ner_result.get('framework', []),
            ner_result.get('method_name', []),
            ner_result.get('technology', [])
        ])

        if not has_entities:
            print("   âŒ è­¦å‘Š: æœªæå–åˆ°ä»»ä½•å®ä½“ï¼")
            return None
        else:
            print("   âœ… æˆåŠŸæå–åˆ°å®ä½“")

    except Exception as e:
        print(f"   âŒ NERæå–å¤±è´¥: {e}")
        logger_debug.error(f"NERæå–å¤±è´¥: {e}")
        return None

    # æ­¥éª¤6ï¼šæ¨¡æ¿åŒ¹é…å’Œå¡«å……
    print("\nğŸ“‹ æ­¥éª¤6: æ¨¡æ¿åŒ¹é…å’Œå¡«å……")
    graph_templates = []

    print(f"   ğŸ“Š å¯ç”¨æ¨¡æ¿æ•°é‡: {len(GRAPH_TEMPLATE)}")
    print(f"   ğŸ“Š æ¨¡æ¿ç±»å‹: {list(GRAPH_TEMPLATE.keys())}")

    for template_name, template in GRAPH_TEMPLATE.items():
        slot = template['slots'][0]  # è·å–æ¨¡æ¿éœ€è¦çš„æ§½ä½
        slot_values = ner_result.get(slot, [])  # ä»NERç»“æœä¸­è·å–å¯¹åº”çš„å®ä½“

        print(f"\n   ğŸ” æ¨¡æ¿: {template_name}")
        print(f"      éœ€è¦æ§½ä½: {slot}")
        print(f"      æå–åˆ°çš„å€¼: {slot_values}")

        if slot_values:
            print(f"      âœ… æ§½ä½åŒ¹é…æˆåŠŸ")
            for value in slot_values:
                filled_template = {
                    'question': replace_token_in_string(template['question'], [[slot, value]]),
                    'cypher': replace_token_in_string(template['cypher'], [[slot, value]]),
                    'answer': replace_token_in_string(template['answer'], [[slot, value]]),
                }
                graph_templates.append(filled_template)
                print(f"         å¡«å……ç»“æœ: {filled_template['question'][:50]}...")
        else:
            print(f"      âŒ æ§½ä½åŒ¹é…å¤±è´¥")

    print(f"\n   âœ… åŒ¹é…åˆ° {len(graph_templates)} ä¸ªæŸ¥è¯¢æ¨¡æ¿")

    if not graph_templates:
        print("   âŒ é”™è¯¯: æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•æ¨¡æ¿ï¼")
        return None

    # æ­¥éª¤7ï¼šç›¸ä¼¼åº¦ç­›é€‰
    print("\nğŸ“‹ æ­¥éª¤7: ç›¸ä¼¼åº¦ç­›é€‰")
    try:
        graph_documents = [
            Document(page_content=template['question'], metadata=template)
            for template in graph_templates
        ]
        print(f"   ğŸ“Š æ„å»ºäº† {len(graph_documents)} ä¸ªæ–‡æ¡£")

        db = FAISS.from_documents(graph_documents, get_embeddings_model())
        graph_documents_filter = db.similarity_search_with_relevance_scores(query, k=3)
        print(f"   ğŸ“Š ç›¸ä¼¼åº¦ç­›é€‰åå‰©ä½™ {len(graph_documents_filter)} ä¸ªæ¨¡æ¿")

        for i, (doc, score) in enumerate(graph_documents_filter):
            print(f"      {i+1}. ç›¸ä¼¼åº¦: {score:.3f}, é—®é¢˜: {doc.page_content[:50]}...")

    except Exception as e:
        print(f"   âŒ ç›¸ä¼¼åº¦ç­›é€‰å¤±è´¥: {e}")
        logger_debug.error(f"ç›¸ä¼¼åº¦ç­›é€‰å¤±è´¥: {e}")
        return None

    # æ­¥éª¤8ï¼šè¿”å›ç»“æœä¾›åç»­æµ‹è¯•
    print("\n" + "=" * 80)
    print("è°ƒè¯•å®Œæˆï¼Œå¯ä»¥è¿›è¡Œå›¾æ•°æ®åº“æŸ¥è¯¢æµ‹è¯•")
    print("=" * 80)

    return {
        'ner_result': ner_result,
        'graph_templates': graph_templates,
        'filtered_templates': graph_documents_filter
    }


def test_neo4j_connection():
    """æµ‹è¯•Neo4jè¿æ¥"""
    print("\n" + "=" * 80)
    print("ğŸ”— æµ‹è¯•Neo4jè¿æ¥")
    print("=" * 80)

    try:
        from src.utils.utils import get_neo4j_conn
        conn = get_neo4j_conn()
        result = conn.run("RETURN 1 AS test").data()
        print(f"   âœ… Neo4jè¿æ¥æˆåŠŸ: {result}")
        return True
    except Exception as e:
        print(f"   âŒ Neo4jè¿æ¥å¤±è´¥: {e}")
        return False


def test_with_sample_data():
    """ä½¿ç”¨ç¤ºä¾‹æ•°æ®æµ‹è¯•å®Œæ•´æµç¨‹"""
    print("\n" + "=" * 80)
    print("ğŸ§ª ä½¿ç”¨ç¤ºä¾‹æ•°æ®æµ‹è¯•")
    print("=" * 80)

    # æ¨¡æ‹ŸNERæå–ç»“æœ
    sample_ner_result = {
        'class_or_interface': ['Spring Boot'],
        'framework': [],
        'method_name': [],
        'technology': []
    }

    print(f"   ğŸ“Š æ¨¡æ‹ŸNERç»“æœ: {sample_ner_result}")

    # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¨¡æ¿åŒ¹é…
    graph_templates = []
    for template_name, template in GRAPH_TEMPLATE.items():
        slot = template['slots'][0]
        slot_values = sample_ner_result.get(slot, [])

        if slot_values:
            for value in slot_values:
                filled_template = {
                    'question': replace_token_in_string(template['question'], [[slot, value]]),
                    'cypher': replace_token_in_string(template['cypher'], [[slot, value]]),
                    'answer': replace_token_in_string(template['answer'], [[slot, value]]),
                }
                graph_templates.append(filled_template)

    print(f"   âœ… ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®åŒ¹é…åˆ° {len(graph_templates)} ä¸ªæ¨¡æ¿")

    if graph_templates:
        print("   ğŸ“‹ å‰3ä¸ªåŒ¹é…çš„æ¨¡æ¿:")
        for i, template in enumerate(graph_templates[:3]):
            print(f"      {i+1}. {template['question']}")
            print(f"         Cypher: {template['cypher'][:100]}...")
    else:
        print("   âŒ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä¹Ÿæ²¡æœ‰åŒ¹é…åˆ°æ¨¡æ¿")


if __name__ == '__main__':
    # 1. æµ‹è¯•ç¤ºä¾‹æ•°æ®
    test_with_sample_data()

    # 2. æµ‹è¯•NERè¿æ¥
    test_neo4j_connection()

    # 3. è°ƒè¯•å®é™…æŸ¥è¯¢
    test_query = "Spring Bootæ˜¯ä»€ä¹ˆï¼Ÿ"
    debug_graph_query(test_query)